{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283dcd2a-1db3-48b1-bb60-815ece09aaea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T05:16:35.817390Z",
     "iopub.status.busy": "2024-10-15T05:16:35.817088Z",
     "iopub.status.idle": "2024-10-15T05:16:37.126861Z",
     "shell.execute_reply": "2024-10-15T05:16:37.126287Z",
     "shell.execute_reply.started": "2024-10-15T05:16:35.817365Z"
    }
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08649c46-c9db-4b90-ba7c-362311fca655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T05:16:37.128383Z",
     "iopub.status.busy": "2024-10-15T05:16:37.127921Z",
     "iopub.status.idle": "2024-10-15T05:16:37.224892Z",
     "shell.execute_reply": "2024-10-15T05:16:37.224351Z",
     "shell.execute_reply.started": "2024-10-15T05:16:37.128359Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_dataset(data, target_shape, name):\n",
    "    pad_neg_one = ['b1', 'b2', 'mask', 'bb']\n",
    "    data_type = data.dtype\n",
    "    if name in pad_neg_one:\n",
    "        print(\"Padding with -1\")\n",
    "        padded_data = np.full(target_shape, -1, dtype=data_type) \n",
    "    else:\n",
    "        padded_data = np.zeros(target_shape, dtype=data_type)\n",
    "    padded_data[:, :data.shape[1]] = data\n",
    "    # print(padded_data.dtype)\n",
    "    return padded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b662ebdb-c6b9-4736-86be-fbe14b64f2e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T05:16:37.458914Z",
     "iopub.status.busy": "2024-10-15T05:16:37.458598Z",
     "iopub.status.idle": "2024-10-15T05:16:37.524529Z",
     "shell.execute_reply": "2024-10-15T05:16:37.523918Z",
     "shell.execute_reply.started": "2024-10-15T05:16:37.458889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recursively copy groups and datasets from the first file\n",
    "def copy_group(src_group, dest_group):\n",
    "    for name, obj in src_group.items():\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            if name in dest_group:\n",
    "                # Group already exists, recursively copy its content\n",
    "                copy_group(obj, dest_group[name])\n",
    "            else:\n",
    "                # Group doesn't exist, create a new one and copy content\n",
    "                new_group = dest_group.create_group(name)\n",
    "                copy_group(obj, new_group)\n",
    "                # print(name)\n",
    "        elif isinstance(obj, h5py.Dataset):\n",
    "            if name in dest_group:\n",
    "                # Dataset already exists, add data to the existing dataset\n",
    "                existing_dataset = dest_group[name]\n",
    "                src_data = obj[...]\n",
    "                existing_data = existing_dataset[...]\n",
    "                # Pad the datasets if needed\n",
    "                if len(existing_data.shape) == 2 and existing_data.shape[1] != src_data.shape[1]:\n",
    "                    max_cols = max(existing_data.shape[1], src_data.shape[1])\n",
    "                    padded_existing_data = pad_dataset(existing_data, (existing_data.shape[0], max_cols), name)\n",
    "                    padded_src_data = pad_dataset(src_data, (src_data.shape[0], max_cols), name)\n",
    "                    merged_dataset = np.concatenate((padded_existing_data, padded_src_data), axis=0)\n",
    "                else:\n",
    "                    merged_dataset = np.concatenate((existing_data, src_data), axis=0)\n",
    "                # print(name)\n",
    "                del dest_group[name]  # Delete existing dataset\n",
    "                dest_group.create_dataset(name, data=merged_dataset)\n",
    "                # print(dest_group[name].shape)\n",
    "            else:\n",
    "                # Dataset doesn't exist, create a new one and copy data\n",
    "                src_group.copy(obj, dest_group)\n",
    "                print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7005a702-1806-4538-bbd2-46dc1c9a98ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T05:18:35.998427Z",
     "iopub.status.busy": "2024-10-15T05:18:35.998113Z",
     "iopub.status.idle": "2024-10-15T05:18:36.003037Z",
     "shell.execute_reply": "2024-10-15T05:18:36.002470Z",
     "shell.execute_reply.started": "2024-10-15T05:18:35.998404Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_multiple_h5_files(h5_files, merged_file):\n",
    "    # Open the first file to merge others into it\n",
    "    with h5py.File(merged_file, 'w') as merged_f:\n",
    "        for i, file in enumerate(h5_files):\n",
    "            if \"p5\" not in file and \"SM\" not in file:\n",
    "                with h5py.File(file, 'r') as f:\n",
    "                    print(f\"Merging {file} into {merged_file}...\")\n",
    "                    copy_group(f, merged_f)  # Recursively copy groups and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e148124f-a84b-4e16-b97d-99a8d93eca53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T05:18:36.858481Z",
     "iopub.status.busy": "2024-10-15T05:18:36.858214Z",
     "iopub.status.idle": "2024-10-15T05:18:36.861970Z",
     "shell.execute_reply": "2024-10-15T05:18:36.861452Z",
     "shell.execute_reply.started": "2024-10-15T05:18:36.858459Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_h5_files_from_directory(directory):\n",
    "    # Get a list of all .h5 files in the specified directory\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.h5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4f2910-eebf-4293-8805-4d7b28862402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-15T06:03:22.217635Z",
     "iopub.status.busy": "2024-10-15T06:03:22.217305Z",
     "iopub.status.idle": "2024-10-15T06:07:31.119467Z",
     "shell.execute_reply": "2024-10-15T06:07:31.118547Z",
     "shell.execute_reply.started": "2024-10-15T06:03:22.217613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging h5_merged/h5_files_test/hhh_test_90.h5 into h5_merged/hhh_eq_mass_points_test.h5...\n",
      "<HDF5 dataset \"MASK\": shape (246198, 3), type \"|b1\">\n",
      "<HDF5 dataset \"fj_charge\": shape (246198, 3), type \"<i8\">\n",
      "<HDF5 dataset \"fj_chargedenergyfrac\": shape (246198, 3), type \"<f8\">\n",
      "<HDF5 dataset \"fj_cosphi\": shape (246198, 3), type \"<f4\">\n",
      "<HDF5 dataset \"fj_ehadovereem\": shape (246198, 3), type \"<f8\">\n",
      "<HDF5 dataset \"fj_eta\": shape (246198, 3), type \"<f4\">\n",
      "<HDF5 dataset \"fj_mass\": shape (246198, 3), type \"<f4\">\n",
      "<HDF5 dataset \"fj_ncharged\": shape (246198, 3), type \"<i8\">\n",
      "<HDF5 dataset \"fj_neutralenergyfrac\": shape (246198, 3), type \"<f8\">\n",
      "<HDF5 dataset \"fj_nneutral\": shape (246198, 3), type \"<i8\">\n",
      "<HDF5 dataset \"fj_phi\": shape (246198, 3), type \"<f4\">\n",
      "<HDF5 dataset \"fj_pt\": shape (246198, 3), type \"<f4\">\n",
      "<HDF5 dataset \"fj_sdmass\": shape (246198, 3), type \"<f4\">\n",
      "<HDF5 dataset \"fj_sinphi\": shape (246198, 3), type \"<f4\">\n",
      "<HDF5 dataset \"fj_tau21\": shape (246198, 3), type \"<f4\">\n",
      "<HDF5 dataset \"fj_tau32\": shape (246198, 3), type \"<f4\">\n",
      "<HDF5 dataset \"MASK\": shape (246198, 10), type \"|b1\">\n",
      "<HDF5 dataset \"btag\": shape (246198, 10), type \"<f4\">\n",
      "<HDF5 dataset \"cosphi\": shape (246198, 10), type \"<f4\">\n",
      "<HDF5 dataset \"eta\": shape (246198, 10), type \"<f4\">\n",
      "<HDF5 dataset \"flavor\": shape (246198, 10), type \"<f4\">\n",
      "<HDF5 dataset \"mass\": shape (246198, 10), type \"<f4\">\n",
      "<HDF5 dataset \"matchedfj\": shape (246198, 10), type \"<i4\">\n",
      "<HDF5 dataset \"phi\": shape (246198, 10), type \"<f4\">\n",
      "<HDF5 dataset \"pt\": shape (246198, 10), type \"<f4\">\n",
      "<HDF5 dataset \"sinphi\": shape (246198, 10), type \"<f4\">\n",
      "<HDF5 dataset \"bb\": shape (246198,), type \"<i8\">\n",
      "<HDF5 dataset \"mask\": shape (246198,), type \"|b1\">\n",
      "<HDF5 dataset \"mh\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"pt\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"bb\": shape (246198,), type \"<i8\">\n",
      "<HDF5 dataset \"mask\": shape (246198,), type \"|b1\">\n",
      "<HDF5 dataset \"mh\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"pt\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"bb\": shape (246198,), type \"<i8\">\n",
      "<HDF5 dataset \"mask\": shape (246198,), type \"|b1\">\n",
      "<HDF5 dataset \"mh\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"pt\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"b1\": shape (246198,), type \"<i8\">\n",
      "<HDF5 dataset \"b2\": shape (246198,), type \"<i8\">\n",
      "<HDF5 dataset \"mask\": shape (246198,), type \"|b1\">\n",
      "<HDF5 dataset \"mh\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"pt\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"b1\": shape (246198,), type \"<i8\">\n",
      "<HDF5 dataset \"b2\": shape (246198,), type \"<i8\">\n",
      "<HDF5 dataset \"mask\": shape (246198,), type \"|b1\">\n",
      "<HDF5 dataset \"mh\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"pt\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"b1\": shape (246198,), type \"<i8\">\n",
      "<HDF5 dataset \"b2\": shape (246198,), type \"<i8\">\n",
      "<HDF5 dataset \"mask\": shape (246198,), type \"|b1\">\n",
      "<HDF5 dataset \"mh\": shape (246198,), type \"<f8\">\n",
      "<HDF5 dataset \"pt\": shape (246198,), type \"<f8\">\n",
      "Merging h5_merged/h5_files_test/hhh_test_80.h5 into h5_merged/hhh_eq_mass_points_test.h5...\n",
      "Merging h5_merged/h5_files_test/hhh_test_100.h5 into h5_merged/hhh_eq_mass_points_test.h5...\n",
      "Merging h5_merged/h5_files_test/hhh_test_110.h5 into h5_merged/hhh_eq_mass_points_test.h5...\n",
      "Merging h5_merged/h5_files_test/hhh_test_150.h5 into h5_merged/hhh_eq_mass_points_test.h5...\n",
      "Merging h5_merged/h5_files_test/hhh_test_160.h5 into h5_merged/hhh_eq_mass_points_test.h5...\n",
      "Merging h5_merged/h5_files_test/hhh_test_130.h5 into h5_merged/hhh_eq_mass_points_test.h5...\n",
      "Merging h5_merged/h5_files_test/hhh_test_170.h5 into h5_merged/hhh_eq_mass_points_test.h5...\n",
      "Merging h5_merged/h5_files_test/hhh_test_140.h5 into h5_merged/hhh_eq_mass_points_test.h5...\n",
      "Merging h5_merged/h5_files_test/hhh_test_120.h5 into h5_merged/hhh_eq_mass_points_test.h5...\n"
     ]
    }
   ],
   "source": [
    "directory = 'h5_merged/h5_files_test'\n",
    "h5_files = get_h5_files_from_directory(directory)\n",
    "merged_file = 'h5_merged/hhh_eq_mass_points_test.h5'\n",
    "merge_multiple_h5_files(h5_files, merged_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae789eba-e830-4c6b-ac15-cba79777594e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-10T18:20:14.081980Z",
     "iopub.status.busy": "2024-10-10T18:20:14.081616Z",
     "iopub.status.idle": "2024-10-10T18:20:14.610913Z",
     "shell.execute_reply": "2024-10-10T18:20:14.609930Z",
     "shell.execute_reply.started": "2024-10-10T18:20:14.081947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (File)\n",
      "  /INPUTS (Group)\n",
      "    /INPUTS/BoostedJets (Group)\n",
      "      /INPUTS/BoostedJets/MASK (Dataset) (24810635, 3) bool\n",
      "      /INPUTS/BoostedJets/fj_charge (Dataset) (24810635, 3) int64\n",
      "      /INPUTS/BoostedJets/fj_chargedenergyfrac (Dataset) (24810635, 3) float64\n",
      "      /INPUTS/BoostedJets/fj_cosphi (Dataset) (24810635, 3) float32\n",
      "      /INPUTS/BoostedJets/fj_ehadovereem (Dataset) (24810635, 3) float64\n",
      "      /INPUTS/BoostedJets/fj_eta (Dataset) (24810635, 3) float32\n",
      "      /INPUTS/BoostedJets/fj_mass (Dataset) (24810635, 3) float32\n",
      "      /INPUTS/BoostedJets/fj_ncharged (Dataset) (24810635, 3) int64\n",
      "      /INPUTS/BoostedJets/fj_neutralenergyfrac (Dataset) (24810635, 3) float64\n",
      "      /INPUTS/BoostedJets/fj_nneutral (Dataset) (24810635, 3) int64\n",
      "      /INPUTS/BoostedJets/fj_phi (Dataset) (24810635, 3) float32\n",
      "      /INPUTS/BoostedJets/fj_pt (Dataset) (24810635, 3) float32\n",
      "      /INPUTS/BoostedJets/fj_sdmass (Dataset) (24810635, 3) float32\n",
      "      /INPUTS/BoostedJets/fj_sinphi (Dataset) (24810635, 3) float32\n",
      "      /INPUTS/BoostedJets/fj_tau21 (Dataset) (24810635, 3) float32\n",
      "      /INPUTS/BoostedJets/fj_tau32 (Dataset) (24810635, 3) float32\n",
      "    /INPUTS/Jets (Group)\n",
      "      /INPUTS/Jets/MASK (Dataset) (24810635, 10) bool\n",
      "      /INPUTS/Jets/btag (Dataset) (24810635, 10) float32\n",
      "      /INPUTS/Jets/cosphi (Dataset) (24810635, 10) float32\n",
      "      /INPUTS/Jets/eta (Dataset) (24810635, 10) float32\n",
      "      /INPUTS/Jets/flavor (Dataset) (24810635, 10) float32\n",
      "      /INPUTS/Jets/mass (Dataset) (24810635, 10) float32\n",
      "      /INPUTS/Jets/matchedfj (Dataset) (24810635, 10) int32\n",
      "      /INPUTS/Jets/phi (Dataset) (24810635, 10) float32\n",
      "      /INPUTS/Jets/pt (Dataset) (24810635, 10) float32\n",
      "      /INPUTS/Jets/sinphi (Dataset) (24810635, 10) float32\n",
      "  /TARGETS (Group)\n",
      "    /TARGETS/bh1 (Group)\n",
      "      /TARGETS/bh1/bb (Dataset) (24810635,) int64\n",
      "      /TARGETS/bh1/mask (Dataset) (24810635,) bool\n",
      "      /TARGETS/bh1/mh (Dataset) (24810635,) float64\n",
      "      /TARGETS/bh1/pt (Dataset) (24810635,) float64\n",
      "    /TARGETS/bh2 (Group)\n",
      "      /TARGETS/bh2/bb (Dataset) (24810635,) int64\n",
      "      /TARGETS/bh2/mask (Dataset) (24810635,) bool\n",
      "      /TARGETS/bh2/mh (Dataset) (24810635,) float64\n",
      "      /TARGETS/bh2/pt (Dataset) (24810635,) float64\n",
      "    /TARGETS/bh3 (Group)\n",
      "      /TARGETS/bh3/bb (Dataset) (24810635,) int64\n",
      "      /TARGETS/bh3/mask (Dataset) (24810635,) bool\n",
      "      /TARGETS/bh3/mh (Dataset) (24810635,) float64\n",
      "      /TARGETS/bh3/pt (Dataset) (24810635,) float64\n",
      "    /TARGETS/h1 (Group)\n",
      "      /TARGETS/h1/b1 (Dataset) (24810635,) int64\n",
      "      /TARGETS/h1/b2 (Dataset) (24810635,) int64\n",
      "      /TARGETS/h1/mask (Dataset) (24810635,) bool\n",
      "      /TARGETS/h1/mh (Dataset) (24810635,) float64\n",
      "      /TARGETS/h1/pt (Dataset) (24810635,) float64\n",
      "    /TARGETS/h2 (Group)\n",
      "      /TARGETS/h2/b1 (Dataset) (24810635,) int64\n",
      "      /TARGETS/h2/b2 (Dataset) (24810635,) int64\n",
      "      /TARGETS/h2/mask (Dataset) (24810635,) bool\n",
      "      /TARGETS/h2/mh (Dataset) (24810635,) float64\n",
      "      /TARGETS/h2/pt (Dataset) (24810635,) float64\n",
      "    /TARGETS/h3 (Group)\n",
      "      /TARGETS/h3/b1 (Dataset) (24810635,) int64\n",
      "      /TARGETS/h3/b2 (Dataset) (24810635,) int64\n",
      "      /TARGETS/h3/mask (Dataset) (24810635,) bool\n",
      "      /TARGETS/h3/mh (Dataset) (24810635,) float64\n",
      "      /TARGETS/h3/pt (Dataset) (24810635,) float64\n"
     ]
    }
   ],
   "source": [
    "def print_hdf5_structure(obj, indent=0):\n",
    "    \"\"\"\n",
    "    Recursively prints the structure of the HDF5 file.\n",
    "    \"\"\"\n",
    "    spaces = '  ' * indent\n",
    "    if isinstance(obj, h5py.File):\n",
    "        print(f\"{spaces}{obj.name} (File)\")\n",
    "    elif isinstance(obj, h5py.Group):\n",
    "        print(f\"{spaces}{obj.name} (Group)\")\n",
    "    elif isinstance(obj, h5py.Dataset):\n",
    "        print(f\"{spaces}{obj.name} (Dataset) {obj.shape} {obj.dtype}\")\n",
    "    else:\n",
    "        print(f\"{spaces}{obj.name} (Unknown)\")\n",
    "\n",
    "    if isinstance(obj, (h5py.File, h5py.Group)):\n",
    "        for key in obj:\n",
    "            item = obj[key]\n",
    "            print_hdf5_structure(item, indent+1)\n",
    "\n",
    "# Replace 'your_file.h5' with the path to your HDF5 file\n",
    "with h5py.File('h5_merged/h5_merged_all.h5', 'r') as f:\n",
    "    print_hdf5_structure(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61e7aa-e022-48f6-bd21-a45b0f9e81f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
